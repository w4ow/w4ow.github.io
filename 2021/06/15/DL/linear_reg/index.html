<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <title>线性回归：原理与实践 | 柴</title>
  
  

  

  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.6.3/css/all.min.css">
  

  
  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon/favicon.ico">
  

  
    <link rel="stylesheet" href="/style.css">
  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
</head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'> </h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-home fa-fw'></i>&nbsp;HOME
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/categories/Computer-Science"
            
            
            id="categoriesComputer-Science">
            <i class='fas fa-laptop-code fa-fw'></i>&nbsp;CS
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/categories/Mathematics"
            
            
            id="categoriesMathematics">
            <i class='fas fa-dice-d20 fa-fw'></i>&nbsp;MATH
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/categories/Literature"
            
            
            id="categoriesLiterature">
            <i class='fas fa-book-reader fa-fw'></i>&nbsp;LIT
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          柴
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/categories/Computer-Science"
                  
                  
                  id="categoriesComputer-Science">
									<i class='fas fa-laptop-code fa-fw'></i>&nbsp;CS
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/categories/Mathematics"
                  
                  
                  id="categoriesMathematics">
									<i class='fas fa-dice-d20 fa-fw'></i>&nbsp;MATH
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/categories/Literature"
                  
                  
                  id="categoriesLiterature">
									<i class='fas fa-book-reader fa-fw'></i>&nbsp;LIT
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/categories/Computer-Science"
                
                  rel="nofollow"
                
                
                id="categoriesComputer-Science">
								<i class='fas fa-laptop-code fa-fw'></i>&nbsp;CS
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/categories/Mathematics"
                
                
                id="categoriesMathematics">
								<i class='fas fa-dice-d20 fa-fw'></i>&nbsp;MATH
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/categories/Literature"
                
                
                id="categoriesLiterature">
								<i class='fas fa-book-reader fa-fw'></i>&nbsp;LIT
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives/"
                
                  rel="nofollow"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;ARCHIVE
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/categories/"
                
                  rel="nofollow"
                
                
                id="categories">
								<i class='fas fa-folder-open fa-fw'></i>&nbsp;CATEGORIES
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/tags/"
                
                  rel="nofollow"
                
                
                id="tags">
								<i class='fas fa-tags fa-fw'></i>&nbsp;TAGS
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  
    <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2021/06/15/DL/linear_reg/">
        线性回归：原理与实践
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2021-06-15</p>
  </a>
</div>

          
        
          
            <div class="new-meta-item date" itemprop="dateUpdated" datetime="2022-03-07T13:29:53+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>updated at 2022-03-07</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/Computer-Science/Deep-Learning/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>Computer Science&nbsp;/&nbsp;Deep Learning</p>
    </a>
  </div>


          
        
          
            
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/ML/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i>&nbsp;<p>ML</p></a></div>


          
        
      </div>
      
        <hr>
      
    </div>
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          <p>线性回归的输出是一个连续值，因此适用于回归问题，例如房价预测、气温预测、股票预测等等，但是作为一个单层神经网络，其预测能力十分有限。本文简要的介绍其原理以及PyTorch实现。</p>
<hr>
<a id="more"></a>


<h2 id="1-理论模型"><a href="#1-理论模型" class="headerlink" title="1. 理论模型"></a>1. 理论模型</h2><p>给定一个随机样本$(\hat y_i, x_{i1}, x_{i2},…,x_{ip})$，一个线性回归模型假设模型的输入(又称回归量)为$(x_{i1}, x_{i2},…,x_{ip})$，模型的输出(又称回归子)为$\hat y_i$。同时我们加入一个误差项$\varepsilon_i$来捕获除了输入自变量之外的任何对输出的影响。</p>
<p>$$<br>y_i = b+w_1x_{i1}+w_2x_{i2}+…+w_px_{ip}+\varepsilon_i<br>$$</p>
<p>当模型只有一个输入自变量，即$p=1$时，模型被称为一元线性回归，反之则为多元线性回归。形式上地，我们可以定义线性回归模型为：</p>
<p>$$<br>\bm{y}=\bm{Xw}+b<br>$$</p>
<hr>
<h2 id="2-模型求解"><a href="#2-模型求解" class="headerlink" title="2. 模型求解"></a>2. 模型求解</h2><h3 id="2-1-最小二乘法"><a href="#2-1-最小二乘法" class="headerlink" title="2.1 最小二乘法"></a>2.1 最小二乘法</h3><p>我们以一元线性回归为例，简单介绍最小二乘法求解模型。<br>给定了若干个实际样本$(\hat y_i, x_i),i=1,2,…,n$，我们需要找出一元线性回归模型$y=b+wx$中的$w$和$b$，使得该模型能够很好地拟合这一组数据。<br>最小二乘法的标准是，所有样本到模型方程的<strong>平方误差</strong>最小。在最小二乘法中，单个样本的平方误差为：</p>
<p>$$<br>l=\frac{1}{2}(\hat y_i-y_i)^2<br>$$</p>
<p>其中，<strong>添加系数</strong>$\frac{1}{2}$<strong>是为了后面对其求导时能够消除系数</strong>。总样本平均误差为：</p>
<p>$$<br>L = \frac{1}{2n}\sum_{i=1}^n(\hat y_i-y_i)^2 = \frac{1}{2n}\sum_{i=1}^n(\hat y_i - (b+wx_i))^2<br>$$</p>
<p>实际上，当我们将$w$和$b$当做求解目标时，那么该方程是关于$w$和$b$的凸函数。凸函数的重要特点就是当其导数为0时取得最小值。因此我们可以对$w$和$b$分别求偏导并令其为0：</p>
<p>$$<br>\begin{aligned}<br>    \frac{\partial L}{\partial b} &amp;= -\sum_{i=1}^n(\hat y_i-b-wx_i)=\sum_{i=1}^n(\hat y_i-b-wx_i)=0 \\<br>    \frac{\partial L}{\partial w} &amp;= -\sum_{i=1}^n(\hat y_i-b-wx_i)x_i=\sum_{i=1}^n(\hat y_i-b-wx_i)x_i=0<br>\end{aligned}<br>$$</p>
<p>因为$x_i, \hat y_i$都是已知的，带入上式即可求得$w,b$。该方法被称为<strong>最小二乘法，二乘即平方的意思</strong>。</p>
<p>同样的，多元线性模型的与上面一致，即求得一组参数$w_i$使得以下方程最小化：</p>
<p>$$<br>L=\frac{1}{2n}\sum_{i=1}^n(\hat y_i-y_i)^2=\frac{1}{2n}\sum_{i=1}^n(\hat y_i - (b+w_1x_{i1}+w_2x_{i2}+…+w_px_{ip}))^2<br>$$</p>
<p>对各参数$w_i$的求解同样使用最小二乘法，先求其偏导，再带入实际值$x_i,y_i$进行求解，不再赘述。</p>
<h3 id="2-2-梯度下降"><a href="#2-2-梯度下降" class="headerlink" title="2.2 梯度下降"></a>2.2 梯度下降</h3><p>在使用偏导求解$w_i$的过程中，小批量随机梯度下降法(Mini-Batch Stochastic Gradient Descent, MBSGD)目前被广泛应用，其算法原理是，首先对$w_i$取随机初始值，然后对$w_i$进行多次迭代，每次迭代都可能降低损失函数$L$的值，由于$L$是凸函数，因此该方法肯定会在$w_i$取到某些值时达到最小值(或极小值)。在每次迭代中，MBSGD会从所有的样本中随机抽取若干个样本构成一个小批量$\mathcal{B}$，并基于这些小批量样本更新$w_i$:</p>
<p>$$<br>w_i \gets w_i - \frac{\eta}{|\mathcal{B}|}\frac{\partial L}{\partial w_i}<br>$$</p>
<p>其中$\eta$为每次更新$w_i$的<strong>步长</strong>，也称为<strong>学习率</strong>。</p>
<hr>
<h2 id="3-PyTorch实战"><a href="#3-PyTorch实战" class="headerlink" title="3. PyTorch实战"></a>3. PyTorch实战</h2><h3 id="3-1-数据集生成以及封装"><a href="#3-1-数据集生成以及封装" class="headerlink" title="3.1 数据集生成以及封装"></a>3.1 数据集生成以及封装</h3><p>假设房价是关于房屋面积$x_1$和房龄$x_2$的二元回归，我们可以令其为$y=2.3x_1+3.4x_2+1.1$，即$b=1.1, \bm{w}=[2.3, 3.4]$。现在我们依照该函数构造一个数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, TensorDataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征数(即自变量输入)个数为2：房屋面积以及房龄</span></span><br><span class="line">num_features = <span class="number">2</span></span><br><span class="line">num_samples = <span class="number">1000</span></span><br><span class="line">data = torch.randn(num_samples, num_features, dtype=torch.float)</span><br><span class="line">true_w = [<span class="number">2.3</span>, <span class="number">3.4</span>]</span><br><span class="line">true_b = <span class="number">1.1</span></span><br><span class="line"></span><br><span class="line">labels = true_w[<span class="number">0</span>] * data[:, <span class="number">0</span>] + true_w[<span class="number">1</span>] * data[:, <span class="number">1</span>] + true_b</span><br><span class="line"><span class="comment"># 添加噪声(误差)</span></span><br><span class="line">labels += torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=labels.shape), dtype=torch.float)</span><br><span class="line"></span><br><span class="line">plt.scatter(data[:, <span class="number">0</span>].numpy(), labels.numpy(), s=<span class="number">1</span>)</span><br><span class="line">plt.scatter(data[:, <span class="number">1</span>].numpy(), labels.numpy(), s=<span class="number">1</span>)</span><br><span class="line">plt.ylabel(<span class="string">'House price'</span>)</span><br><span class="line">plt.legend(labels=[<span class="string">'$x_1$'</span>, <span class="string">'$x_2$'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="/2021/06/15/DL/linear_reg/linear_regression_1.png" width="60%" height="60%">



<p>封装数据集，封装后的数据变为Torch.Tensor数据类型，可以被Torch识别处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = TensorDataset(data, labels)</span><br><span class="line">data_iter = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-初始化参数模型"><a href="#3-2-初始化参数模型" class="headerlink" title="3.2 初始化参数模型"></a>3.2 初始化参数模型</h3><p>将$w$初始化成均值为$0$、标准差为$0.01$的正态随机数矩阵$\mathbb{R}^{2\times 1}$，将$b$初始化为$1$。在之后的模型训练中，因为要对这些参数求梯度，因此要将它们的<code>requires_grad=True</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_features, <span class="number">1</span>)), dtype=torch.float)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, dtype=torch.float)</span><br><span class="line">w.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br><span class="line">b.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(w.shape, b.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">torch.Size([2, 1]) torch.Size([1])</span><br></pre></td></tr></table></figure>

<h3 id="3-3-定义模型"><a href="#3-3-定义模型" class="headerlink" title="3.3 定义模型"></a>3.3 定义模型</h3><p>首先定义我们的回归模型：$$y=\bm{wX}+b$$<br>其平方损失函数为： $$L = \frac{1}{2n}\sum_{i=1}^{n}(\hat y_i-y_i)^2$$<br>模型可学习参数$\bm{w}$和$b$的更新过程为：<br>$$\begin{aligned}<br>w_i &amp;\gets w_i - \frac{\eta}{|\mathcal{B}|}\frac{\partial L}{\partial w_i}\\<br>b &amp;\gets b - \frac{\eta}{|\mathcal{B}|}\frac{\partial L}{\partial b}<br>\end{aligned}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear</span><span class="params">(X, w, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.mm(X, w) + b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_loss</span><span class="params">(y_hat, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.view(y_hat.size())) ** <span class="number">2</span> / <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd</span><span class="params">(params, lr, batch_size)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.data -= lr * param.grad / batch_size</span><br></pre></td></tr></table></figure>

<h3 id="3-4-模型训练"><a href="#3-4-模型训练" class="headerlink" title="3.4 模型训练"></a>3.4 模型训练</h3><p>在训练中，我们多提从数据集中读取小批次样本，通过调用PyTorch中的反向函数<code>backward</code>计算小批量样本的随机梯度，并调用优化算法SGD来迭代可学习参数$\bm{w}$和$b$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.03</span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">model = linear</span><br><span class="line">loss = squared_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        l = loss(model(x, w, b), y).sum()</span><br><span class="line">        l.backward()</span><br><span class="line">        utils.sgd([w, b], lr, batch_size=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        w.grad.data.zero_()</span><br><span class="line">        b.grad.data.zero_()</span><br><span class="line">    train_l = loss(model(data, w, b), labels)</span><br><span class="line">    print(<span class="string">f'epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, loss: <span class="subst">&#123;train_l.mean().item():<span class="number">.4</span>f&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">f'True paras: \t w:<span class="subst">&#123;true_w&#125;</span> \t\t\t b:<span class="subst">&#123;true_b&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'Train result: \t w:<span class="subst">&#123;w.detach().view(<span class="number">1</span>, <span class="number">2</span>).numpy()[<span class="number">0</span>]&#125;</span>, \t b: <span class="subst">&#123;b.detach().numpy()&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">epoch 1, loss: 0.0000</span><br><span class="line">epoch 2, loss: 0.0000</span><br><span class="line">epoch 3, loss: 0.0000</span><br><span class="line">epoch 4, loss: 0.0000</span><br><span class="line">epoch 5, loss: 0.0000</span><br><span class="line"></span><br><span class="line">True paras: 	 w:[2.3, 3.4] 			     b:1.1</span><br><span class="line">Train result: 	 w:[2.2997692 3.4001975], 	 b: [1.0994117]</span><br></pre></td></tr></table></figure>

<p>可以看到，模型通过5次迭代后的结果就已经十分接近真实值了。</p>
<h3 id="3-5-模型的简洁实现"><a href="#3-5-模型的简洁实现" class="headerlink" title="3.5 模型的简洁实现"></a>3.5 模型的简洁实现</h3><p>PyTorch是一个完成度十分高的深度学习框架，其中已经包含了许多定义好的模型，因此我们可以通过调用直接构造第3.3节中的模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, output_dim=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(input_dim, output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model = Linear(num_features)</span><br></pre></td></tr></table></figure>

<p>PyTorch实例化的模型参数是随机的，个人认为是不需要再次随机化的。</p>
<p>同样的，PyTorch也提供了损失函数和优化算法，我们可以方便地直接调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.03</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        out = model(x)</span><br><span class="line">        l = loss(out, y.view(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    print(<span class="string">f'epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, loss: <span class="subst">&#123;l.item():<span class="number">.4</span>f&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">f'True paras: \t w:<span class="subst">&#123;true_w&#125;</span> \t\t\t b:<span class="subst">&#123;true_b&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'Train result: \t w:<span class="subst">&#123;w.detach().view(<span class="number">1</span>, <span class="number">2</span>).numpy()[<span class="number">0</span>]&#125;</span>, \t b: <span class="subst">&#123;b.detach().numpy()&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Ouput:</span><br><span class="line">epoch 1, loss: 0.0001</span><br><span class="line">epoch 2, loss: 0.0002</span><br><span class="line">epoch 3, loss: 0.0002</span><br><span class="line">epoch 4, loss: 0.0001</span><br><span class="line">epoch 5, loss: 0.0001</span><br><span class="line"></span><br><span class="line">True paras: 	 w:[2.3, 3.4] 			     b:1.1</span><br><span class="line">Train result: 	 w:[2.2997692 3.4001975], 	 b: [1.0994117]</span><br></pre></td></tr></table></figure>


        </div>
        
          


  <section class='meta' id="footer-meta">
    <hr>
    <div class='new-meta-box'>
      
    </div>
  </section>


        
        
            <div class="prev-next">
                
                    <section class="prev">
                        <span class="art-item-left">
                            <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;Previous</h6>
                            <h4>
                                <a href="/2021/06/16/Math/Formal_lang/Lec0/" rel="prev" title="形式语言与计算复杂性(零)：绪论">
                                  
                                      形式语言与计算复杂性(零)：绪论
                                  
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/Lecture/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i>Lecture</a>
                                </h6>
                            
                        </span>
                    </section>
                
                
                    <section class="next">
                        <span class="art-item-right" aria-hidden="true">
                            <h6>Next&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                            <h4>
                                <a href="/2021/06/13/CS/Tools/HEXO/" rel="prev" title="HEXO的使用">
                                    
                                        HEXO的使用
                                    
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/HEXO/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i>HEXO</a>
                                </h6>
                            
                        </span>
                    </section>
                
            </div>
        
      </section>
    </article>
  




<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->

  <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX","TeX"],
      linebreaks: { automatic:true },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: { autoNumber: "AMS" },
      noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
      Macros: { href: "{}", bm: "\\boldsymbol" }
    },
    messageStyle: "none"
  });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += (all[i].SourceElement().parentNode.className ? ' ' : '') + 'has-jax';
    }
  });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




  <script>
    window.subData = {
      title: '线性回归：原理与实践',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
        
      
        
          
          
            <section class='widget grid'>
  
<header class='pure'>
  <div><i class="fas fa-map-signs fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;NAVIGATION</div>
  
</header>

  <div class='content pure'>
    <ul class="grid navgation">
      
        <li><a class="flat-box" title="/" href="/"
          
          
          id="home">
          
            <i class="fas fa-home fa-fw" aria-hidden="true"></i>
          
          
        </a></li>
      
        <li><a class="flat-box" title="/archives/" href="/archives/"
          
            rel="nofollow"
          
          
          id="archives">
          
            <i class="fas fa-archive fa-fw" aria-hidden="true"></i>
          
          
        </a></li>
      
        <li><a class="flat-box" title="/tags/" href="/tags/"
          
            rel="nofollow"
          
          
          id="tags">
          
            <i class="fas fa-tags fa-fw" aria-hidden="true"></i>
          
          
        </a></li>
      
        <li><a class="flat-box" title="/categories/" href="/categories/"
          
            rel="nofollow"
          
          
          id="categories">
          
            <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
          
          
        </a></li>
      
    </ul>
  </div>
</section>

          
        
      
        
          
          
            
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;TOC</div>
  
    <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div>
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-理论模型"><span class="toc-text">1. 理论模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-模型求解"><span class="toc-text">2. 模型求解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-最小二乘法"><span class="toc-text">2.1 最小二乘法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-梯度下降"><span class="toc-text">2.2 梯度下降</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-PyTorch实战"><span class="toc-text">3. PyTorch实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-数据集生成以及封装"><span class="toc-text">3.1 数据集生成以及封装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-初始化参数模型"><span class="toc-text">3.2 初始化参数模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-定义模型"><span class="toc-text">3.3 定义模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-模型训练"><span class="toc-text">3.4 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-模型的简洁实现"><span class="toc-text">3.5 模型的简洁实现</span></a></li></ol></li></ol>
    </div>
  </section>


          
        
      
        
          
          
            
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Categories</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/categories/"
    title="categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Computer-Science/" href="/categories/Computer-Science/"><div class='name'>Computer Science</div><div class='badge'>(27)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Computer-Science/Algorithm/" href="/categories/Computer-Science/Algorithm/"><div class='name'>Algorithm</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Computer-Science/C-C/" href="/categories/Computer-Science/C-C/"><div class='name'>C & C++</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Computer-Science/Deep-Learning/" href="/categories/Computer-Science/Deep-Learning/"><div class='name'>Deep Learning</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Computer-Science/Information-Security/" href="/categories/Computer-Science/Information-Security/"><div class='name'>Information Security</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Computer-Science/Linux/" href="/categories/Computer-Science/Linux/"><div class='name'>Linux</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Computer-Science/Operating-System/" href="/categories/Computer-Science/Operating-System/"><div class='name'>Operating System</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box child" title="/categories/Computer-Science/Tools/" href="/categories/Computer-Science/Tools/"><div class='name'>Tools</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Literature/" href="/categories/Literature/"><div class='name'>Literature</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Mathematics/" href="/categories/Mathematics/"><div class='name'>Mathematics</div><div class='badge'>(10)</div></a></li>
        
      </ul>
    </div>
  </section>


          
        
      
        
          
          
            
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-fire fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Tags</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/tags/"
    title="tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/C/" style="font-size: 20.67px; color: #6c6c6c">C++</a> <a href="/tags/Conda/" style="font-size: 14px; color: #999">Conda</a> <a href="/tags/Deadlock/" style="font-size: 14px; color: #999">Deadlock</a> <a href="/tags/GDB/" style="font-size: 14px; color: #999">GDB</a> <a href="/tags/GNN/" style="font-size: 14px; color: #999">GNN</a> <a href="/tags/Git/" style="font-size: 14px; color: #999">Git</a> <a href="/tags/HEXO/" style="font-size: 14px; color: #999">HEXO</a> <a href="/tags/LLVM/" style="font-size: 14px; color: #999">LLVM</a> <a href="/tags/Lecture/" style="font-size: 24px; color: #555">Lecture</a> <a href="/tags/LeetCode/" style="font-size: 14px; color: #999">LeetCode</a> <a href="/tags/MBA/" style="font-size: 20.67px; color: #6c6c6c">MBA</a> <a href="/tags/ML/" style="font-size: 17.33px; color: #828282">ML</a> <a href="/tags/MacOS/" style="font-size: 14px; color: #999">MacOS</a> <a href="/tags/Mathematics/" style="font-size: 14px; color: #999">Mathematics</a> <a href="/tags/PDF/" style="font-size: 14px; color: #999">PDF</a> <a href="/tags/Process/" style="font-size: 20.67px; color: #6c6c6c">Process</a> <a href="/tags/PyTorch/" style="font-size: 14px; color: #999">PyTorch</a> <a href="/tags/RNN/" style="font-size: 14px; color: #999">RNN</a> <a href="/tags/SSH/" style="font-size: 14px; color: #999">SSH</a> <a href="/tags/Sort/" style="font-size: 14px; color: #999">Sort</a> <a href="/tags/String/" style="font-size: 14px; color: #999">String</a> <a href="/tags/Tex/" style="font-size: 14px; color: #999">Tex</a> <a href="/tags/Ubuntu/" style="font-size: 20.67px; color: #6c6c6c">Ubuntu</a> <a href="/tags/哲学/" style="font-size: 14px; color: #999">哲学</a>
    </div>
  </section>


          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
  <br>
  <!-- <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div> -->
  <!-- <div>
    Use
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    as theme
    
    . 
  </div> -->
</footer>
<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>





  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('') {
          $('').backstretch(
          ["https://img.vim-cn.com/a3/7909fde90ed22e7a8d8e27883ba6650d45b234.jpg", "https://img.vim-cn.com/29/793fd576933026ea4e21cdbe298b45fa15eb44.jpg", "https://img.vim-cn.com/1e/7c48afe6c9733c82b31d7c1043e43e9a00bc85.jpg", "https://img.vim-cn.com/74/c4f8924aba84f9ea2bbd1d2b397082c5ed8985.jpg"],
          {
            duration: "60000",
            fade: "25000"
          });
        } else {
          $.backstretch(
          ["https://img.vim-cn.com/a3/7909fde90ed22e7a8d8e27883ba6650d45b234.jpg", "https://img.vim-cn.com/29/793fd576933026ea4e21cdbe298b45fa15eb44.jpg", "https://img.vim-cn.com/1e/7c48afe6c9733c82b31d7c1043e43e9a00bc85.jpg", "https://img.vim-cn.com/74/c4f8924aba84f9ea2bbd1d2b397082c5ed8985.jpg"],
          {
            duration: "60000",
            fade: "25000"
          });
        }
      });
    </script>
  











  <script src="/js/app.js"></script>


  <script src="/js/search.js"></script>




<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "Copied";
  let COPY_FAILURE = "Copy failed";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
